# 📝 Режим "Черновик" для экономии токенов OpenAI

## 🎯 Назначение

Режим "Черновик" позволяет тестировать создание проектов **без трат токенов OpenAI**, используя последний успешный ответ от GPT-4o.

---

## 🚀 Как это работает

### Схема работы

```
1️⃣ Первый запуск (GPT-4o):
   Запрос → GPT-4o анализирует → Ответ возвращается
                                    ↓
                          Сохраняется в кеш:
                          backend/llm/last_llm_response.json

2️⃣ Последующие запуски (Черновик):
   Запрос → Эмулятор загружает кеш → Ответ возвращается
   
   ✅ Мгновенно
   ✅ Без трат токенов
   ✅ Реальный ответ от GPT-4o
```

---

## 💡 Использование

### В UI (фронтенд)

1. **Открыть запрос** - кликнуть на запрос в таблице
2. **Выбрать режим** в левой панели "Контекст запроса":
   
   **📝 Черновик (по умолчанию):**
   - ✅ Использует последний кеш GPT-4o
   - ✅ Без трат токенов
   - ✅ Мгновенная обработка
   - 💡 Используйте для **тестирования** создания проектов
   
   **🤖 GPT-4o:**
   - ⚠️ Реальный анализ через OpenAI API
   - ⚠️ Тратятся токены (~$0.02 за запрос)
   - ⚠️ Обработка ~15-20 секунд
   - 💡 Используйте для **реальных** запросов от КД

3. **Режим автоматически сохраняется** при переключении

### Визуальная индикация

**При анализе в режиме "Черновик":**
```
┌────────────────────────────────────────┐
│ 📝 Загрузка черновика...               │
│ Загрузка кеша • Мгновенно              │
└────────────────────────────────────────┘
```
Цвет: **Желтый** (оранжевая рамка)

**При анализе в режиме "GPT-4o":**
```
┌────────────────────────────────────────┐
│ 🤖 Анализ GPT-4o...                    │
│ Списываются токены • Обработка ~15-20с │
└────────────────────────────────────────┘
```
Цвет: **Зеленый** (зеленая рамка)

---

## ⚙️ Настройка в конфиге

### Файл: `backend/llm_config.yaml`

```yaml
llm:
  use_emulator: false       # false = использовать OpenAI GPT-4o
  fallback_to_emulator: false
  
# Режим эмулятора автоматически использует кеш из:
# backend/llm/last_llm_response.json
```

**Важно:** Файл `last_llm_response.json` автоматически создается/обновляется при каждом успешном вызове GPT-4o.

---

## 📁 Файлы

### Кеш последнего ответа
**Путь:** `/Users/andrei_prygunov/Dev/agent_assistant/backend/llm/last_llm_response.json`

**Формат:**
```json
{
  "project_analysis": {
    "project_title": "Название проекта",
    "project_type": "Фильм",
    "genre": "Драма",
    "roles": [...]
  },
  "contacts": {...},
  "confidence": 0.85,
  "used_emulator": false,
  "model": "gpt-4o"
}
```

**Примечания:**
- ✅ Автоматически создается при успешном GPT-4o анализе
- ✅ Добавлен в `.gitignore` (не коммитится в git)
- ✅ Обновляется при каждом новом успешном анализе
- ✅ Может быть удален вручную для сброса кеша

---

## 🧪 Примеры использования

### Сценарий 1: Первый запуск с новым типом запроса

1. **Переключитесь на "🤖 GPT-4o"**
2. Кликните на запрос
3. GPT-4o проанализирует (15-20 сек, ~$0.02)
4. Ответ сохранится в кеш
5. Проект создается на основе реального анализа

### Сценарий 2: Тестирование создания проектов

1. **Переключитесь на "📝 Черновик"** (по умолчанию)
2. Кликните на запрос
3. Загрузится кешированный ответ (<1 сек, $0)
4. Тестируйте создание проекта сколько угодно раз

### Сценарий 3: Обновление кеша

1. После изменений в промпте/схеме
2. Переключитесь на "🤖 GPT-4o"
3. Проанализируйте один запрос
4. Новый ответ перезапишет кеш
5. Переключитесь обратно на "📝 Черновик"

---

## 💰 Экономия токенов

### Без режима "Черновик"
```
10 тестов создания проекта = 10 вызовов GPT-4o
= ~$0.20
```

### С режимом "Черновик"
```
1 вызов GPT-4o (создание кеша) = ~$0.02
9 тестов с черновиком = $0
────────────────────────────────
ИТОГО: ~$0.02 (экономия 90%)
```

---

## 🔍 Отладка

### Проверка наличия кеша

```bash
ls -lh /Users/andrei_prygunov/Dev/agent_assistant/backend/llm/last_llm_response.json
```

### Просмотр кеша

```bash
cat /Users/andrei_prygunov/Dev/agent_assistant/backend/llm/last_llm_response.json | jq
```

### Удаление кеша (для сброса)

```bash
rm /Users/andrei_prygunov/Dev/agent_assistant/backend/llm/last_llm_response.json
```

### Проверка логов

```bash
# Backend логи
tail -f /tmp/django_server.log | grep -E "(Loaded cached|saved to|Using cached)"

# Поиск использования кеша:
# "🔄 Using cached LLM response from last GPT-4o call"
# "✅ Loaded cached LLM response from..."
```

---

## ⚠️ Важные замечания

1. **Кеш перезаписывается:** Каждый успешный вызов GPT-4o перезаписывает кеш
2. **Один кеш на все запросы:** Эмулятор вернет один и тот же ответ для любого запроса
3. **Для тестирования UI:** Идеально подходит для тестирования создания проектов, ролей, валидации
4. **Не для production:** В production режиме используйте только GPT-4o
5. **Первый запуск:** Если кеша нет, эмулятор вернет тестовые данные по умолчанию

---

## 📊 Статус режима в логах

### Черновик (кеш)
```
INFO 2025-10-10 21:30:00 services 🔄 Using cached LLM response from last GPT-4o call
INFO 2025-10-10 21:30:00 services ✅ Loaded cached LLM response from .../last_llm_response.json
```

### Черновик (тестовые данные)
```
INFO 2025-10-10 21:30:00 services 🧪 Using default test data (no cached LLM response)
```

### GPT-4o (реальный анализ)
```
INFO 2025-10-10 21:30:00 openai_service Analyzing request #123 with OpenAI GPT-4o
INFO 2025-10-10 21:30:15 openai_service Successfully analyzed request #123
INFO 2025-10-10 21:30:15 openai_service Last LLM response saved to .../last_llm_response.json
```

---

**Итог:** Используйте режим "📝 Черновик" для всех тестов и отладки, а "🤖 GPT-4o" только для реальных запросов от КД!

